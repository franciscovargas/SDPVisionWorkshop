{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy/Vision Workshop\n",
    "\n",
    "The purpose of this workshop is to provide some high level description of the vision components showcasing where numpy can be of assistance.\n",
    "\n",
    "## Numpy Basics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# An image in numpy is just a multidimensional array (what one calls a tensor )\n",
    "# an example of one could be :\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 8 by 8 image with 3 color channels as a numpy tensor\n",
    "A = np.arange(64*3).reshape(8,8, 3)\n",
    "plt.imshow(A)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lets have a look at something more familiar matrices and matrix mult !\n",
    "\n",
    "A = np.arange(9).reshape(3,3).astype(float)\n",
    "print \"Matrix A: \\n\", A, \"\\n\"\n",
    "\n",
    "I = np.identity(3)\n",
    "\n",
    "print \"Matrix I: \\n\", I, \"\\n\"\n",
    "\n",
    "# Matrix mult is carried out with the dot function\n",
    "\n",
    "print \"Matrix AI: \\n\", A.dot(I), \"\\n\"\n",
    "print \"Matrix A^{2}: \\n\", A.dot(A), \"\\n\"\n",
    "\n",
    "# Element wise multiplication ( hadamard product):\n",
    "\n",
    "print \"Matrix A * I: \\n\", A * I, \"\\n\"\n",
    "\n",
    "# Likewise division\n",
    "print \"Matrix \\\\frac{A} {(I+1)}: \\n\", A / (I+1), \"\\n\"\n",
    "\n",
    "# Tranpose:\n",
    "\n",
    "print \"A^{T}: \\n\", A.T, \"\\n\"\n",
    "\n",
    "# apply a function elementwise\n",
    "\n",
    "print \"exp(A): \\n\", np.exp(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Shadows\n",
    "\n",
    "Whilst image segmentation and filtering is more of a logical starting point in terms of starting simple with numpy RGB normalization is a good place to start.\n",
    "\n",
    "\n",
    "### RGB Normalization\n",
    "\n",
    "Is the following mapping:\n",
    "\n",
    "\\begin{equation}\n",
    "(R',G', B') := \\left(\\frac{R}{(R+G+B)},\\frac{G}{(R+G+B)}, \\frac{B}{(R+G+B)} \\right) \n",
    "\\end{equation}\n",
    "\n",
    "Where $(R',G', B')$ are the normalized pixel color channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_sample_image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "china = load_sample_image('china.jpg')   \n",
    "print \"China is a 3rd order tensor (multidimensional array): \", china.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display the picture (useful for debuggin vision components by examining frames)\n",
    "plt.imshow(china)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To normalize the image the temptation would be to loo through every pixel\n",
    "# and apply the formula given above nonetheless one can do beter\n",
    "\n",
    "# Sum along the 3rd axis of the tensor\n",
    "# That is for every pixel add up its color channels\n",
    "normalizing_factors = np.sum(china, axis=2)\n",
    "# avoid division by zero\n",
    "normalizing_factors[normalizing_factors == 0] = 1\n",
    "h, w = normalizing_factors.shape\n",
    "print \"new shape: \", normalizing_factors.shape\n",
    "\n",
    "# Now we want to divide elementwise (which numpy allows us to do quite nicely)\n",
    "# But in order for broadcasting to work we need the normalizing_factor tensor3\n",
    "# to have the same order as the china tensor\n",
    "\n",
    "norm_china = china.astype(float) / normalizing_factors.reshape(h, w, 1)\n",
    "plt.imshow(norm_china)\n",
    "plt.show()\n",
    "\n",
    "# Worth to look at normed pitch images to examime potential. Atm the standard\n",
    "# normalization that takes place is in HSV space normalizing the color chanel\n",
    "# Which is not quite the same thing (usefull for image segmentation which I \n",
    "# might cover if I have time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing\n",
    "\n",
    "This bit provides more adavance numpy usage just for showcasing since opencv is the most optimal way of carrying these out. Most of the image processing that will be useful for SDP is that of applying digital filters (bluring the image, extracting edges , etc).\n",
    "\n",
    "The arithmetic operation which one aplies a filter to an image is called convolution:\n",
    "\n",
    "![](http://deeplearning.stanford.edu/wiki/images/6/6c/Convolution_schematic.gif)\n",
    "\n",
    "Where the yellow moving mask is the filter normally reffered to as kernel in computer vision.  The mathematical formulation of convolution for image $I$ and kernel $K$ is the following:\n",
    "\n",
    "\\begin{equation}\n",
    "I_{ouput}(x,y) = \\sum_{i=-\\infty}^{\\infty} \\sum_{j=-\\infty}^{\\infty} I(x -i , y - j)*k(x,y)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "from numpy.lib import stride_tricks as st\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "These are two examples of vectorizing \n",
    "convolution. Both slower than using opencv.\n",
    "Yet still a rich example of how much vectorizing\n",
    "can one do and when it brings an advantage.\n",
    "\n",
    "As an exercise one can add padding to both these functions\n",
    "such that the size of the image is conserved.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def partial_conv(I,k):\n",
    "    \"\"\"\n",
    "    Partially vectorized convolution (2 loops out of 4 removed)\n",
    "    \"\"\"\n",
    "    I_x = I.shape[0]\n",
    "    I_y = I.shape[1]\n",
    "\n",
    "    k_x = k.shape[0]\n",
    "    k_y = k.shape[1]\n",
    "\n",
    "    out = np.zeros((I_x - k_x + 1, I_y - k_y + 1))\n",
    "    o_x = out.shape[0]\n",
    "    o_y = out.shape[1]\n",
    "    \n",
    "    # loops over small things are ok (y)\n",
    "    # Image kernels tend to be small\n",
    "    for y in xrange(k_y):\n",
    "        for x in xrange(k_x):\n",
    "            out += k[y,x] * I[y:o_y+y, x:o_x+x]\n",
    "    return out\n",
    "\n",
    "\n",
    "def vectorized_conv(I, k, stridz=(1,1)):\n",
    "    \"\"\"\n",
    "    Vectorized convolution using numpy strides\n",
    "    Faster for small dim images than the partial vectorization\n",
    "    \"\"\"\n",
    "    h, w = I.shape\n",
    "    k_y, k_x = k.shape\n",
    "    ystep , xstep = stridz\n",
    "    nh, nw = ((h - k_y + 1) / ystep, (w - k_x + 1) / xstep)\n",
    "\n",
    "    # This stride bassically generates a permutation\n",
    "    # matrix which allows to do the convolution operation in a fully\n",
    "    # vectorized form. This also allows automatic striding.\n",
    "    windows = st.as_strided(I,\n",
    "                            (nh, nw, k_y, k_x),\n",
    "                            (I.strides[-2] * ystep,\n",
    "                             I.strides[-1] * xstep,\n",
    "                             I.strides[-2],\n",
    "                             I.strides[-1]))\n",
    "    \n",
    "    # flattening along final dimension allows us to express\n",
    "    # convolution as a matrix mult opp\n",
    "    # flattening along kernel strides\n",
    "    woo = windows.reshape(nh, nw, k_y* k_x)\n",
    "    # flattening kerenel\n",
    "    koo = k.ravel()\n",
    "    \n",
    "    # convolution as matrix multiplication\n",
    "    # equivalent mults: \n",
    "    # dt = np.dot(woo, koo)\n",
    "    # dt = woo.dot(koo)\n",
    "    # O(n^{2.3}) usual bound on fast matrix mult\n",
    "    # using strassen like algorithms\n",
    "    # bottleneck for big images lies partly in this line\n",
    "    dt= np.einsum('ijk, k -> ij', woo, koo)\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.misc import lena\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example image:\n",
    "\n",
    "l = lena()\n",
    "# Edge detection kernels/masks/filters:\n",
    "sobel = np.array([[1, 0, -1],\n",
    "                  [2, 0, -2],\n",
    "                  [1, 0, -1]])\n",
    "\n",
    "laplacian_of_gaussian = np.array([[0, 0, 1, 0, 0],\n",
    "                                  [0, 1, 2, 1, 0],\n",
    "                                  [1, 2, -16, 2, 1],\n",
    "                                  [0, 1, 2, 1, 0],\n",
    "                                  [0, 0, 1, 0, 0] ])\n",
    "\n",
    "\n",
    "#Bluring using a uniform filter\n",
    "uniform = (1 / 25.0)*np.ones((10,10))\n",
    "\n",
    "# Convolutions\n",
    "edge1 = vectorized_conv(l, laplacian_of_gaussian)\n",
    "edge2 = vectorized_conv(l, sobel)\n",
    "blur1 = vectorized_conv(l, uniform)\n",
    "\n",
    "plt.gray()\n",
    "plt.imshow(edge1)\n",
    "plt.show()\n",
    "plt.gray()\n",
    "plt.imshow(edge2)\n",
    "plt.show()\n",
    "plt.gray()\n",
    "plt.imshow(blur1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# But you wan to be doing this kind of thing with open cv\n",
    "# Since specific high usage filters have their own custom\n",
    "# optimizations:\n",
    "import cv2 as cv\n",
    "\n",
    "\n",
    "uniform = (1 / 100.0)*np.ones((10,10))\n",
    "img = np.ones((50,50))\n",
    "\n",
    "# Time benchmarks:\n",
    "%timeit cv.blur(img,(10,10))\n",
    "%timeit cv.filter2D(img,-1,uniform)\n",
    "%timeit vectorized_conv(img, uniform)\n",
    "%timeit partial_conv(img, uniform)\n",
    "\n",
    "# The point of learning how to vectorize is that there are things opencv is\n",
    "# missing like the rgb normalization shown earlier on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation (Hand Calibrated by Default)\n",
    "\n",
    "The segementation covered here will be simple image threshholding. The idea is for a given color channel pick an upper and a lower bound for which your object is in  intensity wise and set everything outside that bound to  0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "# Ouput binary image (will encode the thresholding)\n",
    "bin_out = np.ones((china.shape[0], china.shape[1]))\n",
    "\n",
    "\n",
    "# Color for red channel used to find thresholds\n",
    "flat_red_nc = norm_china[:,:,0].ravel()\n",
    "plt.hist(flat_red_nc, 1000)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Upon inspecting the histogram  (note this can be done algorithmically)\n",
    "# This is quite a complex image so the histogram method is not\n",
    "# the most effective\n",
    "blurr = True\n",
    "if blurr:\n",
    "    norm_china2 =  cv.blur(norm_china,(5,5))\n",
    "else:\n",
    "    norm_china2 = norm_china\n",
    "\n",
    "bin_out[norm_china2[:,:,0] < 0.45 ] = 0\n",
    "bin_out[norm_china2[:,:,0] > 0.59 ] = 0\n",
    "plt.gray()\n",
    "plt.imshow(bin_out)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lets try and find the missing tiles by\n",
    "# Taking a disjunction with the blue channel\n",
    "\n",
    "flat_blue_nc = norm_china[:,:,2].ravel()\n",
    "plt.hist(flat_blue_nc, 1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bin_out_b = np.ones((china.shape[0], china.shape[1]))\n",
    "bin_out_b[norm_china[:,:,2] < 0.38 ] = 0\n",
    "\n",
    "\n",
    "# Morpholocial transform open\n",
    "# Removes noise and inflates week segements (erosion + dilation)\n",
    "open_kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE,(2,2))\n",
    "bin_out_bo = cv.morphologyEx(bin_out_b, cv.MORPH_OPEN, open_kernel)\n",
    "\n",
    "plt.gray()\n",
    "plt.imshow(bin_out_b.astype(int))\n",
    "plt.show()\n",
    "\n",
    "plt.gray()\n",
    "plt.imshow(bin_out_bo.astype(int))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.gray()\n",
    "plt.imshow(bin_out_bo.astype(int) | bin_out.astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
